{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from functools import partial\n",
    "from scipy.stats import mode\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, FunctionTransformer, PowerTransformer, PolynomialFeatures, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_val_score, cross_val_predict, RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, cohen_kappa_score, log_loss, f1_score, median_absolute_error, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.inspection import PartialDependenceDisplay, permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor, ExtraTreesRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklego.linear_model import LADRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sub = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['ID', 'y'], axis = 1)\n",
    "Y = train['y']\n",
    "\n",
    "test = test.drop(columns=\"ID\", axis = 1)\n",
    "skf = RepeatedKFold(n_splits = 10, n_repeats = 1, random_state = 42)\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    \n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    input_layer = tf.keras.Input(shape = (12, ))\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon = 0.00001)(input_layer)\n",
    "    x = tf.keras.layers.Dense(16, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation = 'relu')(x)\n",
    "    output_layer = tf.keras.layers.Dense(1)(x)    \n",
    "\n",
    "    model = tf.keras.Model(inputs = input_layer, outputs = output_layer)\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(0.013, beta_1 = 0.5),\n",
    "                  loss = loss_fn)\n",
    "\n",
    "    return model\n",
    "\n",
    "callbacks_list = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor = 'loss', patience = 30, verbose = 0, mode = 'min', restore_best_weights = True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = 'lr', factor = 0.8, patience = 3, min_lr = 0.00001),\n",
    "        tf.keras.callbacks.TerminateOnNaN()\n",
    "    ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.635067\n",
      "Fold 0 ==> TF oof median absolute error score is ==> 0.9013832092285128\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.636859\n",
      "Fold 1 ==> TF oof median absolute error score is ==> 0.9335693359374986\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.632651\n",
      "Fold 2 ==> TF oof median absolute error score is ==> 0.9388847351074148\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.640356\n",
      "Fold 3 ==> TF oof median absolute error score is ==> 0.9204597473144531\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.641465\n",
      "Fold 4 ==> TF oof median absolute error score is ==> 0.8905342102050824\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.632131\n",
      "Fold 5 ==> TF oof median absolute error score is ==> 0.9148635864257812\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.642037\n",
      "Fold 6 ==> TF oof median absolute error score is ==> 0.9357742309570369\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36106, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.640609\n",
      "Fold 7 ==> TF oof median absolute error score is ==> 0.9224411010742202\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36107, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.637344\n",
      "Fold 8 ==> TF oof median absolute error score is ==> 0.9182113647460994\n",
      "--------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 36107, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 83.643487\n",
      "Fold 9 ==> TF oof median absolute error score is ==> 0.9117172241210909\n",
      "The TF oof median absolute error is 0.9187838745117191\n"
     ]
    }
   ],
   "source": [
    "tf_scores, tf_preds = list(), list()\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(skf.split(X, Y)):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "\n",
    "    print('--------------------------------------------------------------')\n",
    "    \n",
    "    x_train = X_train.copy()\n",
    "    x_test = X_test.copy()\n",
    "    test_cv = test.copy()\n",
    "    \n",
    "    ##########\n",
    "    ## LGBM ##\n",
    "    ##########\n",
    "    \n",
    "    LGBM_md = LGBMRegressor().fit(X_train, Y_train)\n",
    "\n",
    "    x_train.loc[:, 'LGBM_1'] = LGBM_md.predict(X_train)\n",
    "    x_test.loc[:, 'LGBM_1'] = LGBM_md.predict(X_test)\n",
    "    test_cv.loc[:, 'LGBM_1'] = LGBM_md.predict(test)\n",
    "    \n",
    "    ########\n",
    "    ## NN ##\n",
    "    ########\n",
    "    \n",
    "    nn_md = create_model()\n",
    "    nn_md.fit(x_train, Y_train,\n",
    "              epochs = 100, \n",
    "              verbose = 0, \n",
    "              callbacks = callbacks_list)\n",
    "    \n",
    "    tf_md_pred = nn_md.predict(x_test, verbose = 0)\n",
    "    tf_md_pred_test = nn_md.predict(test_cv, verbose = 0)\n",
    "    tf_preds.append(tf_md_pred_test)\n",
    "    \n",
    "    tf_score = median_absolute_error(Y_test, tf_md_pred)\n",
    "    \n",
    "    tf_scores.append(tf_score)\n",
    "    print('Fold', i, '==> TF oof median absolute error score is ==>', tf_score)\n",
    "\n",
    "print(f\"The TF oof median absolute error is {np.mean(tf_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>83.490631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>82.553543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>90.023483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>90.564728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>82.456024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID          y\n",
       "0  TEST_0000  83.490631\n",
       "1  TEST_0001  82.553543\n",
       "2  TEST_0002  90.023483\n",
       "3  TEST_0003  90.564728\n",
       "4  TEST_0004  82.456024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_oof_preds = pd.DataFrame(np.concatenate(tf_preds, axis = 1))\n",
    "\n",
    "submission_4 = sub.copy()\n",
    "submission_4['y'] = tf_oof_preds.apply(np.median, axis = 1)\n",
    "submission_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_4.to_csv('TF_sub.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
